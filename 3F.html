
<!doctype html>
<html>
<head>
<meta charset="UTF-8">
<meta name="description" content="Solutions to Linear Algebra Done Right 3rd version, Chapter 3, exercise 3F"/>
<link rel="canonical" href="http://linearalgebras.com/3F.html" />
<meta property="og:locale" content="en_US" />
<meta property="og:type" content="article" />
<meta property="og:title" content="Solutions to Linear Algebra Done Right Chapter 3 exercise 3F" />
<meta property="og:description" content="Solutions to Linear Algebra Done Right 3rd version, Chapter 3, exercise 3F" />
<meta property="og:url" content="http://linearalgebras.com/3F.html" />
<meta property="og:site_name" content="Solutions to Linear Algebra Done Right 3rd Edition" />
<meta property="article:tag" content="Chapter 3" />
<meta property="article:tag" content="Solution" />
<meta property="article:section" content="Linear Algebra" />
<meta property="article:published_time" content="2014-12-07T15:53:58+00:00" />
<meta property="article:modified_time" content="2015-05-09T11:11:19+00:00" />
<meta property="og:updated_time" content="2015-05-09T11:11:19+00:00" />
<title>Solutions to Linear Algebra Done Right 3rd Edition</title>
<link rel="stylesheet" type="text/css" href="styles.css" />
<link rel="stylesheet" type="text/css" href="jquery-ui.css" />
<script type="text/javascript" src="jquery.min.js"></script>
<script type="text/javascript" src="jquery-ui.min.js"></script>
</head>

<body>
<div id="wrap">
    <div id="header">
        <img src="resolcone.png" />
        <div id="title">
            <h1>Solutions to Linear Algebra Done Right 3rd Edition</h1>
            <h2 style="font-weight: normal;">May 18-21, 2015<br/>
                Third Edition </h2>
        </div>
    </div>
    
    <div id="main">
    
    <div id="nav">
        <ul>
            <li ><a href="index.html">Homepage</a></li>
            <li ><a href="1A.html">Exercises 1.A</a></li>
            <li ><a href="1B.html">Exercises 1.B</a></li>
            <li ><a href="1C.html">Exercises 1.C</a></li>
            <li ><a href="2A.html">Exercises 2.A</a></li>
            <li ><a href="2B.html">Exercises 2.B</a></li>
            <li ><a href="2C.html">Exercises 2.C</a></li>
            <li ><a href="3A.html">Exercises 3.A</a></li>
            <li ><a href="3B.html">Exercises 3.B</a></li>
            <li ><a href="3C.html">Exercises 3.C</a></li>
            <li ><a href="3D.html">Exercises 3.D</a></li>
            <li ><a href="3E.html">Exercises 3.E</a></li>
            <li class='selected'><a href="3F.html">Exercises 3.F</a></li>
            <li ><a href="4.html">Exercises 4</a></li>
            <li ><a href="5A.html">Exercises 5.A</a></li>
            <li ><a href="5B.html">Exercises 5.B</a></li>
            <li ><a href="5C.html">Exercises 5.C</a></li>
            <li ><a href="6A.html">Exercises 6.A</a></li>
            <li ><a href="6B.html">Exercises 6.B</a></li>
            <li ><a href="6C.html">Exercises 6.C</a></li>
            <li ><a href="7A.html">Exercises 7.A</a></li>
            <li ><a href="7B.html">Exercises 7.B</a></li>
            <li ><a href="7C.html">Exercises 7.C</a></li>
        </ul>
    </div>
        
    <div id="content">
    
<h2 align="right">Chapter 3 Exercise F</h2>
<hr/>
<p>1. Explain why every linear functional is either surjective or the zero map.</p>
<p>Solution: For any $\vp\in\ca L(V,\mb F)$, if $\dim \m{range} V=0$, then $\vp$ is the zero map. If $\dim \m{range} V=1$, then $\vp$ is surjective since $\dim\mb F=1$. Moreover, $\dim \m{range} V\leqslant \dim \mb F=1$. Hence, that is all the possible cases.</p>
<hr />
<p>2. Give three distinct examples of linear functionals on $\R^{[0,1]}$.</p>
<p>Solution: Let $\vp_1,\vp_2,\vp_3\in\ca L(\R^{[0,1]},\mb F)$ defined by \[\vp_1(f)=f(0),\quad\vp_2(f)=f(0.5),\quad\vp_3(f)=f(1).\]Please check that $\vp_1,\vp_2,\vp_3\in\ca L(\R^{[0,1]},\mb F)$ and they are different from each other.</p>
<hr />
<p>3. Suppose $V$ is finite-dimensional and $v\in V$ with $v\ne 0$. Prove that there exists $\vp\in V&#8217;$ such that $\vp(v)=1$.</p>
<p>Solution: Extend $v$ to a basis of $V$ and use 3.96.</p>
<hr />
<p>4. Suppose $V$ is finite-dimensional and $U$ is a subspace of $V$ such that $U\ne V$. Prove that there exists $\vp\in V&#8217;$ such that $\vp(u)=0$ for every $u\in U$ but $\vp\ne 0$.</p>
<p>Solution: Let $u_1$, $\cdots$, $u_m$ be a basis of $U$, since $U\ne V$ we can extend it to a basis of $V$ as $u_1$, $\cdots$, $u_m$, $u_{m+1}$, $\cdots$, $v_{m+n}$, where $n\geqslant 1$. Hence we can define $\vp\in V&#8217;$ by \[\vp(u_i)=\left\{ \begin{array}{ll} 0, &amp; \hbox{if $i\ne m+1$;} \\ 1, &amp; \hbox{if $i=m+1$.} \end{array} \right. \]Then $\vp\in V&#8217;$ and $\vp(u)=0$ for every $u\in U$ but $\vp\ne 0$.</p>
<hr />
<p>5. Suppose $V_1$, $\cdots$, $V_m$ are vector spaces. Prove that $(V_1\times\cdots\times V_m)&#8217;$ and $V&#8217;_1\times\cdots\times V&#8217;_m$ are isomorphic vector spaces.</p>
<p>Solution: Define $P_i\in\ca L(V_i,V_1\times\cdots\times V_m)$ by \[P_i(x)=(0,\cdots,0,x,0,\cdots,0)\]with $x$ in the $i$-th component. Define $\vp\in \ca L((V_1\times\cdots\times V_m)&#8217;,V&#8217;_1\times\cdots\times V&#8217;_m)$ by \[\vp(f)=(P&#8217;_1f,\cdots,P&#8217;_mf).\]Now let us check that $\vp$ is an isomorphism.</p>
<p>Injectivity: suppose $(P&#8217;_1f,\cdots,P&#8217;_mf)=0$, that is for any $(x_1,\cdots,x_m)\in V_1\times\cdots\times V_m$, we have \[ P&#8217;_if(x_i)=0\Longrightarrow f(0,\cdots,x_i,\cdots,0)=0 \]by the definition of $P_i$ and dual map. This implies \[f(x_1,\cdots,x_m)=\sum_{i=1}^mf(0,\cdots,x_i,\cdots,0)=0,\]namely $f=0$. Thus $\vp$ is injective. Here $(0,\cdots,x_i,\cdots,0)$ means the $i$-th component is $x_i$ and all other components are zero.</p>
<p>Surjectivity: for any $(f_1,\cdots,f_m)\in V&#8217;_1\times\cdots\times V&#8217;_m$, define $f\in (V_1\times\cdots\times V_m)&#8217;$ by \[f(x_1,\cdots,x_m)=\sum_{i=1}^mf_i(x_i).\]Then we can easily check that $\vp f=(f_1,\cdots,f_m)$.</p>
<p>By the arguments above, it follows that $(V_1\times\cdots\times V_m)&#8217;$ and $V&#8217;_1\times\cdots\times V&#8217;_m$ are isomorphic.</p>
<hr />
<p>6. Suppose $V$ is finite-dimensional and $v_1,\cdots,v_m\in V$. Define a linear map $\Gamma: V&#8217;\to\mb F^m$ by \[\Gamma(\vp)=(\vp(v_1),\cdots,\vp(v_m))\] (a) Prove that $v_1,\cdots,v_m$ spans $V$ if and only if $\Gamma$ is injective.</p>
<p>(b) Prove that $v_1,\cdots,v_m$ is linearly independent if and only if $\Gamma$ is surjective.</p>
<p>Solution: (a) If $v_1,\cdots,v_m$ spans $V$, then $\Gamma(\vp)=0$ implies \[\vp(v_1)=\cdots=\vp(v_m)=0.\]Hence $\vp=0$ since $v_1,\cdots,v_m$ spans $V$. Specifically, for any $v\in V$, we can write \[v=\sum_{k_i}v_i,\quad k_i\in\mb F.\]Thus \[\vp(v)=\vp\left(\sum_{i=1}^mk_iv_i\right)=\sum_{i=1}^mk_i\vp(v_i)=0.\]This implies $\vp=0$. We conclude $\Gamma$ is injective.</p>
<p>If $\Gamma$ is injective and $\m{span}(v_1,\cdots,v_m)\ne V$, then by Problem 4, there exists a $\vp\in V&#8217;$ such that \[\vp(\m{span}(v_1,\cdots,v_m))=0\]and $\vp\ne 0$. This implies $\Gamma$ is not injective. We get a contradiction. Hence $v_1,\cdots,v_m$ spans $V$.</p>
<p>(b) If $v_1,\cdots,v_m$ is linearly independent, then for any $(f_1,\cdots,f_m)\in\mb F^m$, there exists a $\vp\in V&#8217;$ such that \[\vp(v_i)=f_i,\quad i=1,\cdots,m.\]This is easy to show by extending $v_1,\cdots,v_m$ to a basis of $V$ and using 3.5. Then by definition of $\Gamma$, we have\[\Gamma(\vp)=(f_1,\cdots,f_m).\]This implies $\Gamma$ is surjective.</p>
<p>If $\Gamma$ is surjective, suppose $v_1,\cdots,v_m$ is linearly dependent. Then there exist $k_1,\cdots,k_m\in\mb F$ such that \[k_1v_1+\cdots+k_mv_m=0\]and some $k_i$ is nonzero. Let $k_i\ne 0$, then $v_i$ can be written as a linear combination of $v_1,\cdots,v_{i-1}$,$v_{i+1},\cdots,v_n$. Hence, $(0,\cdots,0,1,0,\cdots,0)$ is not in $\m{range}\Gamma$, where $1$ is on the $i$-th component. Otherwise, we have $\vp\in V&#8217;$ such that $\Gamma(\vp)=(0,\cdots,0,1,0,\cdots,0)$. Then \[\vp(v_j)=0,\vp(v_i)=1,j=1,\cdots,i-1,i+1,\cdots,m.\]This implies $\vp(v)=0$ if $v$ is a linear combination of $v_1,\cdots,v_{i-1}$,$v_{i+1},\cdots,v_n$. Thus $\vp(v_i)=0$ by our previous argument. However, we also have $\vp(v_i)=1$. Therefore this can not happen, namely $\Gamma$ is not surjective. That means that the assumption that $v_1,\cdots,v_m$ is linearly dependent can never happen. Hence $v_1,\cdots,v_m$ is linearly independent.</p>
<hr />
<p>7. Suppose $m$ is a positive integer. Show that the dual basis of the basis $1,x,\cdots,x_m$ of $\ca P_m(\R)$ is $\vp_0,\vp_1,\cdots,\vp_m$, where $\vp_j(p)=\frac{p^{(j)}(0)}{j!}$. Here $p^{(j)}$ denotes the $j^{\m{th}}$ derivative of $p$, with the understanding that the $0^{\m{th}}$ derivative of $p$ is $p$.</p>
<p>Solution: By calculating them directly, we have \[ \vp_j(x^i)=\delta_{i,j}, \]where $\delta_{i,j}=1$ if $i=j$ and $\delta_{i,j}=0$ if $i\ne j$. Note that the dual basis of one given basis is unique(if exist). Hence we have the dual basis of the basis $1,x,\cdots,x_m$ of $\ca P_m(\R)$ is $\vp_0,\vp_1,\cdots,\vp_m$.</p>
<hr />
<p>8. Suppose $m$ is a positive integer.</p>
<p>(a) Show that $1,x-5,\cdots,(x-5)_m$ is a basis of $\ca P_m(\R)$ .</p>
<p>(b) What is the dual basis of the basis in part (a)?</p>
<p>Solution: (a) This is easy, see <a title="EXERCISES OF CHAPTER 2 C" href="/2C.html" target="_blank">Problem 10 of Exercise 2C</a>.</p>
<p>(b) The dual basis of the basis $1,x-5,\cdots,(x-5)_m$ of $\ca P_m(\R)$ is $\vp_0,\vp_1,\cdots,\vp_m$, where $\vp_j(p)=\frac{p^{(j)}(5)}{j!}$. Here $p^{(j)}$ denotes the $j^{\m{th}}$ derivative of $p$, with the understanding that the $0^{\m{th}}$ derivative of $p$ is $p$. The proof is similar to Problem 7.</p>
<hr />
<p>9. Suppose $v_1,\cdots,v_n$ is a basis of $V$ and $\vp_1,\cdots,\vp_n$ is the corresponding dual basis of $V&#8217;$. Suppose $\psi\in V&#8217;$. Prove that \[\psi=\psi(v_1)\vp_1+\cdots+\psi(v_n)\vp_n.\]Solution: Note $v_1,\cdots,v_n$ is a basis of $V$ and $\vp_1,\cdots,\vp_n$ is the corresponding dual basis of $V&#8217;$, we have \[(\psi(v_1)\vp_1+\cdots+\psi(v_n)\vp_n)(v_1)=\psi(v_1).\]Similarly, we also have\[(\psi(v_1)\vp_1+\cdots+\psi(v_n)\vp_n)(v_i)=\psi(v_i).\]Hence\[\psi=\psi(v_1)\vp_1+\cdots+\psi(v_n)\vp_n,\]as they coincide at a basis of $V$.</p>
<hr />
<p>10. Prove the first two bullet points in 3.101.</p>
<p>Solution: (a) $(S+T)&#8217;=S&#8217;+T&#8217;$ for all $S,T\in\ca L(V,W)$. For each $\vp\in W&#8217;$, we have \begin{align*} (S+T)'(\vp)(x)&amp;=\vp((S+T)x)=\vp(Sx+Tx)=\vp(Sx)+\vp(Tx)\\&amp;=S'(\vp)(x)+T'(\vp)(x)=(S&#8217;+T&#8217;)(\vp)(x) \end{align*} for all $x\in W$. The first and forth equality hold by the definition of dual map (3.99). The other ones hold by 3.6. Hence $(S+T)'(\vp)=(S&#8217;+T&#8217;)(\vp)$ for each $\vp\in W&#8217;$, namely $(S+T)&#8217;=S&#8217;+T&#8217;$.</p>
<p>(b) $(\lambda T)&#8217;=\lambda T&#8217;$ for all $\lambda\in\mb F$ and all $T\in\ca L(V,W)$. For each $\vp\in W&#8217;$, we have \begin{align*} (\lambda T)'(\vp)(x)&amp;=\vp((\lambda T)x)=\vp(\lambda Tx)=\lambda\vp( Tx)\\&amp;=\lambda T'(\vp)(x)=(\lambda T&#8217;)(\vp)(x) \end{align*}for all $x\in W$. Here we also use 3.6 and 3.99. Similarly, we conclude $(\lambda T)&#8217;=\lambda T&#8217;$.</p>
<hr />
<p>16. Suppose $V$ and $W$ are finite-dimensional. Prove that the map that takes $T\in\ca L(V,W)$ to $T&#8217;\in\ca L(W&#8217;,V&#8217;)$ is an isomorphism of $\ca L(V,W)$ onto $\ca L(W&#8217;,V&#8217;)$.</p>
<p>Solution: Let $\Gamma:\ca L(V,W)\to \ca L(W&#8217;,V&#8217;)$ defined by \[\Gamma(T)=T&#8217;.\]By 3.60, we have $\dim \ca L(V,W)=\dim \ca L(W&#8217;,V&#8217;)$. Hence, by 3.69, it suffices to show $\Gamma$ is injective. Suppose $\Gamma(S)=0$ for some $S\in \ca L(V,W)$, that is $S&#8217;=0$. Hence for any $\vp\in W&#8217;$ and $v\in V$, we have \[S'(\vp)(v)=\vp(Sv)=0.\]By Problem 3, this can only happen when $Sv=0$. Hence $Sv=0$ for all $v\in V$. Thus $S=0$. We conclude $\Gamma$ is injective.</p>
<hr />
<p>17. Suppose $U\subset V$. Explain why $U^0=\{\vp\in V':U\subset \m{null}\vp\}$.</p>
<p>Solution: Note that\[\vp(u)=0\text{ for all } u\in U\iff U\subset \m{null}\vp.\]</p>
<hr />
<p>18. Suppose $V$ is finite-dimensional and $U\subset V$. Show that $U=\{0\}$ if and only if $U^0=V&#8217;$.</p>
<p>Solution: By Problem 17, $U^0=V&#8217;$ if and only if $U\subset \m{null}\vp$ for all $\vp\in V&#8217;$. Note that by Problem 3, $v\in\m{null}\vp$ for all $\vp\in V&#8217;$ if and only if $v=0$. This implies $U^0=V&#8217;$ if and only if $U=\{0\}$.</p>
<p>Other solution: by 3.106, we have \[\dim U+\dim U^0=\dim V.\]Hence\[\dim U^0=\dim V&#8217;\iff \dim U=0\] since $\dim V&#8217;=\dim V$.</p>
<hr />
<p>19. Suppose $V$ is finite-dimensional and $U$ is a subspace of $V$. Show that $U=V$ if and only if $U^0=\{0\}$.</p>
<p>Solution: By 3.106, we have \[\dim U+\dim U^0=\dim V.\]Hence \[\dim U=\dim V\iff \dim U^0=0.\]That is $U=V$ if and only if $U^0=\{0\}$.</p>
<hr />
<p>20. Suppose $U$ and $W$ are subsets of $V$ with $U\subset W$. Prove that $W^0\subset U^0$.</p>
<p>Solution: If $\vp\in W^0$, then $\vp(w)=0$ for all $w\in W$. As $U\subset W$, we also have $\vp(u)=0$ for all $u\in W$, hence $\vp\in U^0$. Since $\vp$ is chosen arbitrarily, we deduce that $W^0\subset U^0$.</p>

        <center>
            <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <!-- IH -->
            <ins class="adsbygoogle"
                 style="display:inline-block;width:728px;height:90px"
                 data-ad-client="ca-pub-5289197296725423"
                 data-ad-slot="8213787797">
             </ins>
            <script>(adsbygoogle = window.adsbygoogle || []).push({});</script>
        </center>

    <div id="disqus_thread"></div>
  </div>
</div> <!-- close #main -->
<div id="footer">
    <div> 
        <p>Please only read these solutions after you have already thought about it carefully. Do not just copy these solutions.</p>
    </div>
</div><!-- close #footer -->
</div><!-- close #wrap -->
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = 'linearalg';
    
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
<script type="text/x-mathjax-config">
                    MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"],scale: 90, linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50), },
                    tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], displayMath: [ ["$$","$$"], ["\\[", "\\]"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
                     TeX: {  equationNumbers: {autoNumber: ["AMS"], useLabelIds: true},noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}",beqn:"\\begin{eqnarray}",eeqn:"\\end{equation}",beq:"\\begin{eqnarray}",eeq:"\\end{eqnarray}",be:"\\begin{equation}",ee:"\\end{eqnarray}",ca:"\\mathcal",m:"\\mathrm",mf:"\\mathbf",mb:"\\mathbb",N:"{\\mathbb{N}}",Z:"{\\mathbb{Z}}",R:"{\\mathbb{R}}",C:"{\\mathbb{C}}",vp:"{\\varphi}",e:"{\\epsilon}" } },
                                        messageStyle: "none"
                }); 
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Queue(["Typeset",MathJax.Hub]);
</script></script><script type='text/x-mathjax-config'>
    MathJax.Hub.Config({
        TeX: {equationNumbers: {autoNumber: ["AMS"], useLabelIds: true}},
        "HTML-CSS": {linebreaks: {automatic: true}},
        SVG: {linebreaks: {automatic: true}}
    });
</script>
</body>
</html>